{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz6CwD6MRWFs"
      },
      "source": [
        "##Install Requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD9uOPEK65K0"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AwVn7yc7Soj"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git\n",
        "%cd /content/MedViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RPHDM3KwQ4Ys"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-1.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 2.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 9.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting scikit-image\n",
            "  Downloading scikit_image-0.24.0-cp39-cp39-macosx_12_0_arm64.whl (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 12.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 11.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 19.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting Pillow\n",
            "  Downloading pillow-11.0.0-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fire\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-2.5.0-cp39-none-macosx_11_0_arm64.whl (64.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 64.3 MB 4.1 MB/s eta 0:00:014\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.20.0-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
            "\u001b[K     |████████████████████████████████| 447 kB 5.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting safetensors\n",
            "  Downloading safetensors-0.4.5-cp39-cp39-macosx_11_0_arm64.whl (383 kB)\n",
            "\u001b[K     |████████████████████████████████| 383 kB 6.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 8.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting scipy>=1.6.0\n",
            "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.3 MB 4.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting joblib>=1.2.0\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 4.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting lazy-loader>=0.4\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging>=21 in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from scikit-image->-r requirements.txt (line 7)) (24.1)\n",
            "Collecting networkx>=2.8\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 6.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tifffile>=2022.8.12\n",
            "  Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 4.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting imageio>=2.33\n",
            "  Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
            "\u001b[K     |████████████████████████████████| 315 kB 6.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting termcolor>=1.1\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 4.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting requests~=2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 5.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting sympy==1.13.1\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/nuha/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (4.12.2)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 4.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 4.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.15.0)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 4.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 3.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 3.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
            "Building wheels for collected packages: fvcore, fire, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61433 sha256=cd6f2f75aefaaeb1d5eccaf074451f6dd6fec5ead3b9ca27840e3e1cdc4a5edb\n",
            "  Stored in directory: /Users/nuha/Library/Caches/pip/wheels/83/42/02/66178d16e5c44dc26d309931834956baeda371956e86fbd876\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114262 sha256=11b83b00f98f28f6844e1c5c93e4106c04efb4cb5c04b86829aa543aae7e13a1\n",
            "  Stored in directory: /Users/nuha/Library/Caches/pip/wheels/3b/ee/ac/319a7b7f331f61050d0d54425079b2a883b445be3c7284a4eb\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31550 sha256=dfab116e7de0c363f6d350ef584231c60c7dd3f2d63122752dd66969d8f2ace0\n",
            "  Stored in directory: /Users/nuha/Library/Caches/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
            "Successfully built fvcore fire iopath\n",
            "Installing collected packages: mpmath, MarkupSafe, urllib3, sympy, Pillow, networkx, jinja2, idna, fsspec, filelock, chardet, certifi, tqdm, torch, tifffile, threadpoolctl, termcolor, scipy, requests, pyyaml, portalocker, lazy-loader, joblib, imageio, yacs, torchvision, tabulate, scikit-learn, scikit-image, safetensors, iopath, huggingface-hub, fire, torchattacks, timm, medmnist, fvcore, einops\n",
            "Successfully installed MarkupSafe-3.0.2 Pillow-11.0.0 certifi-2024.8.30 chardet-4.0.0 einops-0.8.0 filelock-3.16.1 fire-0.7.0 fsspec-2024.10.0 fvcore-0.1.5.post20221221 huggingface-hub-0.26.1 idna-2.10 imageio-2.36.0 iopath-0.1.10 jinja2-3.1.4 joblib-1.4.2 lazy-loader-0.4 medmnist-3.0.2 mpmath-1.3.0 networkx-3.2.1 portalocker-2.10.1 pyyaml-6.0.2 requests-2.25.1 safetensors-0.4.5 scikit-image-0.24.0 scikit-learn-1.5.2 scipy-1.13.1 sympy-1.13.1 tabulate-0.9.0 termcolor-2.5.0 threadpoolctl-3.5.0 tifffile-2024.8.30 timm-1.0.11 torch-2.5.0 torchattacks-3.5.1 torchvision-0.20.0 tqdm-4.66.5 urllib3-1.26.20 yacs-0.1.8\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deLoJPfDTDWl"
      },
      "outputs": [],
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIefIFDW80-U"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVNzCWaVUd_1"
      },
      "source": [
        "data_flag =  \n",
        "[tissuemnist, pathmnist, chestmnist, dermamnist, octmnist, pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "outputs": [],
      "source": [
        "data_flag = 'retinamnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(\"number of channels : \", n_channels)\n",
        "print(\"number of classes : \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD22o8uW9L1X"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNjqCTnI9T9w"
      },
      "outputs": [],
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ta2wQYk78Mg"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a17pPgePWXga"
      },
      "source": [
        "MedViTs ---> [MedViT_small, MedViT_base, MedViT_large]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEQ5S3_U8E0j",
        "outputId": "0ea09038-9e57-42ab-b767-592098af81ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ],
      "source": [
        "from MedViT import MedViT_small, MedViT_base, MedViT_large\n",
        "\n",
        "model = MedViT_small(num_classes = n_classes).cuda()\n",
        "#model = MedViT_base(num_classes = n_classes).cuda()\n",
        "#model = MedViT_large(num_classes = n_classes).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ImKp2m9cLf"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "outputs": [],
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmIo3JWf9lEs"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRkfM6CM91j8"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdC1Gg98RU37",
        "outputId": "11f6b052-2ac0-4080-c31d-cb5c4cdf0ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test  auc: 0.623  acc: 0.472\n"
          ]
        }
      ],
      "source": [
        "split = 'test'\n",
        "\n",
        "model.eval()\n",
        "y_true = torch.tensor([])\n",
        "y_score = torch.tensor([])\n",
        "\n",
        "data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in data_loader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.softmax(dim=-1)\n",
        "        y_score = torch.cat((y_score, outputs.cpu()), 0)\n",
        "\n",
        "    y_score = y_score.detach().numpy()\n",
        "\n",
        "    evaluator = Evaluator(data_flag, split, size=224)\n",
        "    metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "    print('%s  auc: %.3f  acc: %.3f' % (split, *metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH1WvchMX5L0"
      },
      "source": [
        "## Adversarial Robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GER2-X0Yc1ZL"
      },
      "source": [
        "reduce bach size for GPU limitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rNHm98NaZjZ5"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 5\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK4kV6p9YiZY"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = FGSM(model, eps=0.01)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('FGSM Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76g3n07lcW8x"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = PGD(model, eps=8/255, alpha=4/255, steps=10, random_start=True)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('PGD Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
