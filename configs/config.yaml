# configs/config.yaml

project:
  name: "Epistemic Uncertainty Project"
  description: "Ruhani's PhD Dissertation project on EUFairGAN."

dataloader:
  batch_size: 32
  shuffle: true
  num_workers: 4  # Number of subprocesses for data loading

temp_training:
  learning_rate: 0.001
  num_epochs: 100
  optimizer: "adam"  # Specify the optimizer to use (e.g., adam, sgd)
  loss_function: "cross_entropy"  # Specify the loss function

training:
  learning_rate: 0.005
  num_epochs: 100
  optimizer: "adam"  # Specify the optimizer to use (e.g., adam, sgd)
  loss_function: "nn.CrossEntropyLoss"  # Specify the loss function


check_medvit_test:
  model_pth: 'outputs/medvit_base/medvit_mnist__base_wt10.pt'

check_bnn_medvit_test:
  model_pth: 'outputs/bnn_medvit_base/medvit_mnist__base_wt34.pt'

test_bnn:

  medvit_test:
    desc: 'Dataset: NIHCC Chest Xray, Model: MedViT, Task: Age Prediction, Outclass: 3, Optim: Adam, lr: 0.001, batch: 32, #train_samples: 14K'
    bnn_model_location: 'medvit_mnist__base_wt75.pt'
    dataset: 'UTKFace'
    model_class: 'MedViT'
    hyperparameters:
      learning_rate: 0.005
      epochs: 100
      batch_size: 32
      optimizer: 'adam'

  utkface_gender:
    desc: 'Dataset: UTKFace, Model: CNNModel, Task: Age Prediction, Outclass: 3, Optim: Adam, lr: 0.001, batch: 32, #train_samples: 14K'
    bnn_model_location: 'outputs/train_bnn_utkface_cnn_UTKFace_20241010_200858/models/model_weights__epoch50_lr0.001_20241010_200858..pth'
    dataset: 'UTKFace'
    model_class: 'CNNModel'
    hyperparameters:
      learning_rate: 0.001
      epochs: 100
      batch_size: 32
      optimizer: 'adam'

  celeba_gender:
    desc: 'Dataset: CelebA, Model: CNNModel, Task: Smiling or Not, Outclass: 2, Optim: Adam, lr: 0.001, batch: 32, #train_samples: 144K'
    bnn_model_location: 'outputs/train_bnn_celeba_cnn_CelebA_20241011_005353/models/model_weights__epoch10_lr0.001_20241011_005353..pth'
    dataset: 'UTKFace'
    model_class: 'CNNModel'
    hyperparameters:
      learning_rate: 0.001
      epochs: 100
      batch_size: 32
      optimizer: 'adam'
